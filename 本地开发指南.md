# Long-Novel-GPT 本地开发指南

## 概述

本指南介绍如何在本地环境中运行 Long-Novel-GPT，无需依赖 Docker。

## 环境要求

### 必需软件
- **Python**: 3.8+ (推荐 3.10+)
- **Conda**: 用于虚拟环境管理
- **Git**: 用于代码管理

### 系统兼容性
- ✅ macOS
- ✅ Linux
- ✅ Windows (详见 [Windows开发指南.md](Windows开发指南.md))

## 快速开始

### 1. 环境准备

```bash
# 克隆项目（如果还未克隆）
git clone <repository-url>
cd Long-Novel-GPT

# 创建conda虚拟环境
conda create -n long-novel-gpt python=3.10
conda activate long-novel-gpt

# 安装Python依赖
pip install -r requirements.txt
```

### 2. 配置环境变量

```bash
# 复制环境配置文件
cp .env.local.example .env

# 编辑配置文件，至少配置一个API
nano .env  # 或使用其他编辑器
```

**重要**: 必须配置至少一个 AI API 才能正常使用系统。

### 3. 启动服务

#### 方式1: 使用Shell脚本（推荐）

```bash
# 给脚本执行权限
chmod +x start_local.sh

# 启动服务
./start_local.sh
```

#### 方式2: 使用Python脚本

```bash
python start_local.py
```

#### 方式3: 手动启动

```bash
# 终端1: 启动后端
cd backend
python app.py

# 终端2: 启动前端
python frontend_server.py
```

### 4. 访问应用

- **前端地址**: http://localhost:8080
- **后端API**: http://localhost:7869

## 配置说明

### 端口配置

可以通过环境变量自定义端口:

```bash
export FRONTEND_PORT=8080    # 前端端口
export BACKEND_PORT=7869     # 后端端口
export BACKEND_HOST=127.0.0.1  # 后端监听地址
```

### API配置

在 `.env` 文件中配置至少一个 AI API:

#### 智谱AI (推荐)
```bash
ZHIPUAI_API_KEY=your_api_key
ZHIPUAI_AVAILABLE_MODELS=glm-4-air,glm-4-flashx
DEFAULT_MAIN_MODEL=zhipuai/glm-4-air
DEFAULT_SUB_MODEL=zhipuai/glm-4-flashx
```

#### 其他支持的API
- **文心一言**: 配置 `WENXIN_AK` 和 `WENXIN_SK`
- **豆包**: 配置 `DOUBAO_API_KEY` 和 `DOUBAO_ENDPOINT_IDS`
- **OpenAI GPT**: 配置 `GPT_API_KEY` 和 `GPT_BASE_URL`
- **本地模型**: 配置 `LOCAL_BASE_URL` 和 `LOCAL_API_KEY`

## 目录结构

```
Long-Novel-GPT/
├── backend/                # 后端代码
│   ├── app.py             # Flask应用入口
│   ├── requirements.txt   # 后端依赖
│   └── ...
├── frontend/              # 前端代码
│   ├── index.html        # 主页面
│   ├── js/               # JavaScript文件
│   ├── styles/           # CSS样式
│   └── data/             # 示例数据
├── core/                  # 核心功能模块
├── llm_api/              # LLM API接口
├── prompts/              # 提示词模板
├── requirements.txt      # 项目依赖
├── start_local.sh        # Shell启动脚本
├── start_local.py        # Python启动脚本
├── frontend_server.py    # 前端开发服务器
├── .env.local.example    # 本地环境配置模板
└── 本地开发指南.md        # 本文档
```

## 开发说明

### 依赖管理

项目依赖已整理到根目录的 `requirements.txt` 文件中，主要包括:

- **Flask**: Web框架
- **Flask-CORS**: 跨域支持
- **OpenAI**: OpenAI API客户端
- **qianfan**: 百度千帆API客户端
- **zhipuai**: 智谱AI客户端
- **pymongo**: MongoDB客户端（可选）
- **rich**: 终端美化工具

### 前端服务器

`frontend_server.py` 提供了一个开发用的前端服务器，具有以下特性:

- 静态文件服务
- API请求代理到后端
- CORS支持
- 自动错误处理

### 调试模式

后端会在以下情况启用调试模式:
- 检测到开发环境
- `FLASK_DEBUG=True` 环境变量

## 常见问题

### 1. 端口被占用

如果默认端口被占用，可以修改环境变量:

```bash
export FRONTEND_PORT=8081
export BACKEND_PORT=7870
./start_local.sh
```

### 2. API配置问题

确保在 `.env` 文件中正确配置了API密钥和模型:

```bash
# 检查配置
cat .env | grep -E "(API_KEY|WENXIN|ZHIPUAI|DOUBAO|GPT)"
```

### 3. 依赖安装失败

确保使用了正确的Python环境:

```bash
# 检查当前conda环境
conda info --envs

# 重新安装依赖
pip install -r requirements.txt --force-reinstall
```

### 4. 前端无法访问后端

检查后端是否正常启动:

```bash
# 测试后端健康检查
curl http://localhost:7869/health
```

## 与Docker版本的区别

### 优势
- **开发便利**: 无需构建镜像，直接修改代码
- **调试方便**: 可以直接使用IDE调试功能
- **资源占用**: 不需要Docker daemon，资源占用更低
- **启动速度**: 启动速度更快

### 注意事项
- 需要手动管理Python环境和依赖
- MongoDB等外部服务需要单独安装配置
- 生产环境建议仍使用Docker部署

## 贡献指南

1. Fork 项目
2. 创建特性分支: `git checkout -b feature/your-feature`
3. 提交更改: `git commit -am 'Add some feature'`
4. 推送分支: `git push origin feature/your-feature`
5. 提交Pull Request

## 许可证

请参考项目根目录的 LICENSE 文件。