#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
åŠ¨æ€é…ç½®ç®¡ç†å™¨
è´Ÿè´£è¿è¡Œæ—¶åŠ¨æ€ç®¡ç†AIæä¾›å•†é…ç½®ï¼Œæ”¯æŒé€šè¿‡Webç•Œé¢å®æ—¶æ›´æ–°è®¾ç½®
"""

import json
import os
import threading
from typing import Dict, Any, List, Optional
from dataclasses import dataclass, asdict

@dataclass
class ProviderConfig:
    """AIæä¾›å•†é…ç½®"""
    name: str
    api_key: str
    model_name: str
    base_url: Optional[str] = None
    models: List[str] = None
    system_prompt: str = ""
    
    def __post_init__(self):
        if self.models is None:
            self.models = []

class DynamicConfigManager:
    """åŠ¨æ€é…ç½®ç®¡ç†å™¨"""
    
    def __init__(self):
        self._config_lock = threading.RLock()
        self._current_provider = "deepseek"
        self._providers = {}
        self._load_default_configs()
        # å°è¯•ä»æ–‡ä»¶åŠ è½½é…ç½®
        self.load_config_from_file()
    
    def _load_default_configs(self):
        """åŠ è½½é»˜è®¤é…ç½®"""
        default_configs = {
            "deepseek": ProviderConfig(
                name="deepseek",
                api_key="",
                model_name="deepseek-chat",
                base_url="https://api.deepseek.com/v1",
                models=["deepseek-chat", "deepseek-coder", "deepseek-reasoner"]
            ),
            "aliyun": ProviderConfig(
                name="aliyun",
                api_key="", 
                model_name="qwen-max",
                base_url="https://dashscope.aliyuncs.com/api/v1",
                models=["qwen-max", "qwen-plus", "qwen-turbo", "qwen2.5-72b-instruct"]
            ),
            "zhipuai": ProviderConfig(
                name="zhipuai",
                api_key="",
                model_name="glm-4-air",
                base_url=None,
                models=["glm-4-air", "glm-4-flashx", "glm-4-plus", "glm-4v-plus"]
            ),
            "lmstudio": ProviderConfig(
                name="lmstudio",
                api_key="lm-studio",
                model_name="local-model",
                base_url="http://localhost:1234/v1",
                models=["local-model"]
            ),
            "gemini": ProviderConfig(
                name="gemini",
                api_key="",
                model_name="gemini-pro",
                base_url="https://generativelanguage.googleapis.com",
                models=["gemini-pro", "gemini-pro-vision", "gemini-1.5-pro", "gemini-1.5-flash"]
            ),
            "openrouter": ProviderConfig(
                name="openrouter",
                api_key="",
                model_name="openai/gpt-4",
                base_url="https://openrouter.ai/api/v1",
                models=[
                    "openai/gpt-4", "openai/gpt-3.5-turbo",
                    "anthropic/claude-3-opus", "anthropic/claude-3-sonnet",
                    "google/gemini-pro", "meta-llama/llama-2-70b-chat"
                ]
            ),
            "claude": ProviderConfig(
                name="claude",
                api_key="",
                model_name="claude-3-5-sonnet-20241022",
                base_url="https://api.anthropic.com",
                models=[
                    "claude-3-opus-20240229", "claude-3-sonnet-20240229", 
                    "claude-3-haiku-20240307", "claude-3-5-sonnet-20241022",
                    "claude-3-5-haiku-20241022"
                ]
            )
        }
        
        with self._config_lock:
            self._providers = default_configs
    
    def get_provider_list(self) -> List[str]:
        """è·å–æ‰€æœ‰æ”¯æŒçš„æä¾›å•†åˆ—è¡¨"""
        with self._config_lock:
            return list(self._providers.keys())
    
    def get_provider_models(self, provider_name: str) -> List[str]:
        """è·å–æŒ‡å®šæä¾›å•†çš„æ¨¡å‹åˆ—è¡¨"""
        with self._config_lock:
            if provider_name not in self._providers:
                return []
            return self._providers[provider_name].models.copy()
    
    def get_current_provider(self) -> str:
        """è·å–å½“å‰ä½¿ç”¨çš„æä¾›å•†"""
        with self._config_lock:
            return self._current_provider
    
    def get_provider_config(self, provider_name: str) -> Optional[ProviderConfig]:
        """è·å–æŒ‡å®šæä¾›å•†çš„é…ç½®"""
        with self._config_lock:
            return self._providers.get(provider_name)
    
    def get_current_config(self) -> Optional[ProviderConfig]:
        """è·å–å½“å‰æä¾›å•†çš„é…ç½®"""
        with self._config_lock:
            return self._providers.get(self._current_provider)
    
    def update_provider_config(self, provider_name: str, config: Dict[str, Any]) -> bool:
        """æ›´æ–°æä¾›å•†é…ç½®"""
        with self._config_lock:
            if provider_name not in self._providers:
                return False
            
            provider_config = self._providers[provider_name]
            
            # æ›´æ–°åŸºæœ¬é…ç½®
            if 'api_key' in config:
                provider_config.api_key = config['api_key']
            if 'model_name' in config:
                provider_config.model_name = config['model_name']
            if 'base_url' in config:
                provider_config.base_url = config['base_url']
            if 'system_prompt' in config:
                provider_config.system_prompt = config['system_prompt']
            if 'models' in config:
                provider_config.models = config['models']
                
            return True
    
    def set_current_provider(self, provider_name: str) -> bool:
        """è®¾ç½®å½“å‰ä½¿ç”¨çš„æä¾›å•†"""
        with self._config_lock:
            if provider_name not in self._providers:
                return False
            self._current_provider = provider_name
            return True
    
    def save_config_to_file(self, config_path: str = "runtime_config.json"):
        """ä¿å­˜é…ç½®åˆ°æ–‡ä»¶"""
        try:
            config_data = {}
            
            with self._config_lock:
                config_data["current_provider"] = self._current_provider
                config_data["providers"] = {}
                
                for name, provider_config in self._providers.items():
                    config_data["providers"][name] = asdict(provider_config)
            
            # æ–‡ä»¶æ“ä½œåœ¨é”å¤–è¿›è¡Œ
            with open(config_path, 'w', encoding='utf-8') as f:
                json.dump(config_data, f, ensure_ascii=False, indent=2)
            
            print(f"é…ç½®å·²ä¿å­˜åˆ° {config_path}")
            return True
        except Exception as e:
            print(f"ä¿å­˜é…ç½®å¤±è´¥: {e}")
            return False
    
    def load_config_from_file(self, config_path: str = "runtime_config.json"):
        """ä»æ–‡ä»¶åŠ è½½é…ç½®"""
        if not os.path.exists(config_path):
            print(f"é…ç½®æ–‡ä»¶ {config_path} ä¸å­˜åœ¨ï¼Œä½¿ç”¨é»˜è®¤é…ç½®")
            return False
        
        try:
            with open(config_path, 'r', encoding='utf-8') as f:
                config_data = json.load(f)
            
            with self._config_lock:
                self._current_provider = config_data.get("current_provider", "deepseek")
                
                # åŠ è½½æä¾›å•†é…ç½®
                for name, provider_data in config_data.get("providers", {}).items():
                    if name in self._providers:
                        # æ›´æ–°ç°æœ‰é…ç½®
                        config = self._providers[name]
                        config.api_key = provider_data.get("api_key", config.api_key)
                        config.model_name = provider_data.get("model_name", config.model_name)
                        config.system_prompt = provider_data.get("system_prompt", config.system_prompt)
                        if "base_url" in provider_data:
                            config.base_url = provider_data["base_url"]
                        if "models" in provider_data:
                            config.models = provider_data["models"]
            
            print(f"é…ç½®å·²ä» {config_path} åŠ è½½")
            return True
        except Exception as e:
            print(f"åŠ è½½é…ç½®å¤±è´¥: {e}")
            return False
    
    def validate_config(self, provider_name: str) -> bool:
        """éªŒè¯é…ç½®æ˜¯å¦æœ‰æ•ˆ"""
        with self._config_lock:
            if provider_name not in self._providers:
                return False
            
            config = self._providers[provider_name]
            
            # å¯¹äºéæœ¬åœ°æä¾›å•†ï¼Œæ£€æŸ¥APIå¯†é’¥
            if provider_name != "lmstudio":
                if not config.api_key or "your-" in config.api_key.lower():
                    return False
            
            return True
    
    def test_provider_connection(self, provider_name: str, config: Dict[str, Any]) -> Dict[str, Any]:
        """æµ‹è¯•æä¾›å•†è¿æ¥"""
        print(f"\n=== Testing Provider Connection ===")
        print(f"Provider: {provider_name}")
        print(f"Config: {config}")
        
        try:
            # åŸºæœ¬éªŒè¯
            if not config.get('api_key'):
                error_msg = "APIå¯†é’¥ä¸èƒ½ä¸ºç©º"
                print(f"âŒ {error_msg}")
                return {"success": False, "error": error_msg}
            
            if not config.get('model_name'):
                error_msg = "æ¨¡å‹åç§°ä¸èƒ½ä¸ºç©º"
                print(f"âŒ {error_msg}")
                return {"success": False, "error": error_msg}
            
            # å®ç°çœŸå®çš„APIè¿æ¥æµ‹è¯•
            from llm_api import test_stream_chat, ModelConfig
            
            # æ„å»ºæ¨¡å‹é…ç½®
            model_config = ModelConfig(
                model=config['model_name'],
                api_key=config['api_key'],
                max_tokens=100  # æµ‹è¯•æ—¶ä½¿ç”¨å°çš„tokenæ•°
            )
            
            # æ·»åŠ ç‰¹å®šæä¾›å•†çš„é…ç½®
            if provider_name == 'openrouter' or config.get('base_url'):
                model_config['base_url'] = config.get('base_url', 'https://openrouter.ai/api/v1')
            
            if provider_name == 'lmstudio':
                model_config['base_url'] = config.get('base_url', 'http://localhost:1234/v1')
            
            print(f"ğŸ§ª Testing with model config: {dict(model_config)}")
            
            # æ‰§è¡Œæµ‹è¯•
            test_result = ""
            for response in test_stream_chat(model_config):
                test_result += response
                if len(test_result) > 50:  # é™åˆ¶æµ‹è¯•å“åº”é•¿åº¦
                    break
            
            print(f"âœ… Connection test successful")
            print(f"Test response: {test_result[:100]}...")
            
            return {
                "success": True, 
                "message": f"è¿æ¥åˆ° {provider_name} æˆåŠŸ",
                "test_response": test_result[:100] + "..." if len(test_result) > 100 else test_result
            }
            
        except Exception as e:
            error_msg = f"è¿æ¥æµ‹è¯•å¤±è´¥: {str(e)}"
            print(f"âŒ {error_msg}")
            import traceback
            traceback.print_exc()
            return {"success": False, "error": error_msg}
        finally:
            print(f"=== Provider Connection Test Finished ===\n")
    
    def load_provider_models(self, provider_name: str, config: Dict[str, Any]) -> Dict[str, Any]:
        """åŠ è½½æä¾›å•†çš„æ¨¡å‹åˆ—è¡¨"""
        try:
            if provider_name == "lmstudio":
                return self._load_lmstudio_models(config)
            elif provider_name == "openrouter":
                return self._load_openrouter_models(config)
            elif provider_name in self._providers:
                default_models = self._providers[provider_name].models
                return {"success": True, "models": default_models}
            else:
                return {"success": False, "error": "ä¸æ”¯æŒçš„æä¾›å•†"}
                
        except Exception as e:
            return {"success": False, "error": str(e)}
    
    def _load_lmstudio_models(self, config: Dict[str, Any]) -> Dict[str, Any]:
        """ä»LM StudioåŠ è½½æ¨¡å‹åˆ—è¡¨"""
        try:
            import requests
            
            base_url = config.get('base_url', 'http://localhost:1234/v1')
            api_key = config.get('api_key', 'lm-studio')
            
            # è°ƒç”¨LM Studioçš„/v1/modelsæ¥å£
            response = requests.get(
                f"{base_url}/models",
                headers={"Authorization": f"Bearer {api_key}"},
                timeout=10
            )
            response.raise_for_status()
            
            models_data = response.json()
            model_names = [model["id"] for model in models_data.get("data", [])]
            
            if not model_names:
                model_names = ["local-model"]  # é»˜è®¤æ¨¡å‹ä½œä¸ºå¤‡ç”¨
            
            return {"success": True, "models": model_names}
            
        except Exception as e:
            print(f"Failed to load LM Studio models: {e}")
            return {"success": False, "error": f"æ— æ³•è¿æ¥åˆ°LM Studio: {str(e)}"}
    
    def _load_openrouter_models(self, config: Dict[str, Any]) -> Dict[str, Any]:
        """ä»OpenRouter APIåŠ è½½å¹¶è¿‡æ»¤æ¨¡å‹åˆ—è¡¨"""
        try:
            import requests
            
            base_url = config.get('base_url', 'https://openrouter.ai/api/v1')
            
            print(f"OpenRouter config - base_url: {base_url}")
            
            # è°ƒç”¨OpenRouterçš„/v1/modelsæ¥å£ï¼ˆä¸éœ€è¦API keyï¼‰
            url = f"{base_url}/models"
            headers = {
                "User-Agent": "Long-Novel-GPT/1.0",
                "Content-Type": "application/json"
            }
            
            print(f"Making request to: {url}")
            print(f"Headers: {headers}")
            
            response = requests.get(url, headers=headers, timeout=30)
            print(f"Response status: {response.status_code}")
            
            response.raise_for_status()
            
            models_data = response.json()
            total_models = len(models_data.get("data", []))
            print(f"Total models from API: {total_models}")
            
            # è¿‡æ»¤æŒ‡å®šæä¾›å•†çš„æ¨¡å‹
            target_providers = ["openai", "google", "qwen", "deepseek", "grok", "x-ai"]
            filtered_models = []
            
            for model in models_data.get("data", []):
                model_id = model.get("id", "")
                for provider in target_providers:
                    if model_id.startswith(f"{provider}/"):
                        filtered_models.append(model_id)
                        break
            
            print(f"Filtered models count: {len(filtered_models)}")
            print(f"First 10 filtered models: {filtered_models[:10]}")
            
            if not filtered_models:
                # å¦‚æœæ²¡æœ‰æ‰¾åˆ°æ¨¡å‹ï¼Œè¿”å›é»˜è®¤æ¨¡å‹
                print("No models found, using default models")
                filtered_models = [
                    "openai/gpt-4o", "openai/gpt-4o-mini", "openai/gpt-4-turbo",
                    "google/gemini-1.5-pro", "google/gemini-1.5-flash",
                    "deepseek/deepseek-chat", "deepseek/deepseek-r1",
                    "qwen/qwen-2.5-72b-instruct", "qwen/qwen-max",
                    "x-ai/grok-beta"
                ]
            
            return {"success": True, "models": filtered_models}
            
        except Exception as e:
            print(f"Failed to load OpenRouter models: {e}")
            import traceback
            traceback.print_exc()
            return {"success": False, "error": f"æ— æ³•è¿æ¥åˆ°OpenRouter API: {str(e)}"}
    
    def get_all_configs(self) -> Dict[str, Any]:
        """è·å–æ‰€æœ‰é…ç½®ä¿¡æ¯"""
        with self._config_lock:
            result = {
                "current_provider": self._current_provider,
                "providers": {}
            }
            
            for name, config in self._providers.items():
                # ä¸è¿”å›æ•æ„Ÿä¿¡æ¯ï¼ˆAPIå¯†é’¥ï¼‰
                safe_config = asdict(config)
                if safe_config.get('api_key'):
                    api_key = safe_config['api_key']
                    if len(api_key) > 8:
                        safe_config['api_key'] = api_key[:4] + "***" + api_key[-4:]
                    else:
                        safe_config['api_key'] = "***"
                
                result["providers"][name] = safe_config
            
            return result

# å…¨å±€é…ç½®ç®¡ç†å™¨å®ä¾‹
_config_manager = None
_config_lock = threading.Lock()

def get_config_manager() -> DynamicConfigManager:
    """è·å–å…¨å±€é…ç½®ç®¡ç†å™¨å®ä¾‹ï¼ˆå•ä¾‹æ¨¡å¼ï¼‰"""
    global _config_manager
    if _config_manager is None:
        with _config_lock:
            if _config_manager is None:
                _config_manager = DynamicConfigManager()
    return _config_manager

if __name__ == "__main__":
    # æµ‹è¯•é…ç½®ç®¡ç†å™¨
    manager = get_config_manager()
    print("æ”¯æŒçš„æä¾›å•†:", manager.get_provider_list())
    print("å½“å‰æä¾›å•†:", manager.get_current_provider())
    print("å½“å‰é…ç½®:", manager.get_current_config())