# APIé…ç½®ç®¡ç†æ–‡æ¡£

## æ¦‚è¿°

æœ¬æ–‡æ¡£è¯¦ç»†ä»‹ç»Long-Novel-GPTæ”¯æŒçš„æ‰€æœ‰AIæä¾›å•†çš„é…ç½®æ–¹æ³•ã€å‚æ•°è¯´æ˜å’Œæœ€ä½³å®è·µã€‚

## æ”¯æŒçš„APIæä¾›å•†

### 1. DeepSeek API

**ç‰¹ç‚¹ï¼š**
- é«˜æ€§ä»·æ¯”ï¼Œä¸­æ–‡ä¼˜åŒ–
- æ”¯æŒé•¿ä¸Šä¸‹æ–‡
- å“åº”é€Ÿåº¦å¿«

**é…ç½®å‚æ•°ï¼š**
```json
{
  "name": "deepseek",
  "api_key": "sk-your-deepseek-api-key",
  "model_name": "deepseek-chat",
  "base_url": "https://api.deepseek.com/v1",
  "models": ["deepseek-chat", "deepseek-coder", "deepseek-reasoner"],
  "system_prompt": ""
}
```

**è·å–APIå¯†é’¥ï¼š**
1. è®¿é—® [DeepSeekå¼€æ”¾å¹³å°](https://platform.deepseek.com/)
2. æ³¨å†Œå¹¶ç™»å½•è´¦æˆ·
3. åœ¨æ§åˆ¶å°ä¸­åˆ›å»ºAPIå¯†é’¥
4. å¤åˆ¶å¯†é’¥åˆ°é…ç½®æ–‡ä»¶

**ä½¿ç”¨ç¤ºä¾‹ï¼š**
```python
# ç¯å¢ƒå˜é‡é…ç½®
export DEEPSEEK_API_KEY="sk-your-key-here"
export DEEPSEEK_MODEL="deepseek-chat"

# ä»£ç é…ç½®
config = {
    "api_key": "sk-your-key-here",
    "model": "deepseek-chat",
    "base_url": "https://api.deepseek.com/v1",
    "max_tokens": 4096
}
```

### 2. OpenAI API

**ç‰¹ç‚¹ï¼š**
- æœ€å…ˆè¿›çš„GPTæ¨¡å‹
- æ”¯æŒå¤šç§æ¨¡å¼
- ç”Ÿæ€ç³»ç»Ÿå®Œå–„

**é…ç½®å‚æ•°ï¼š**
```json
{
  "name": "openai",
  "api_key": "sk-your-openai-api-key",
  "model_name": "gpt-4",
  "base_url": "https://api.openai.com/v1",
  "models": ["gpt-4", "gpt-4-turbo", "gpt-3.5-turbo"],
  "system_prompt": ""
}
```

**è·å–APIå¯†é’¥ï¼š**
1. è®¿é—® [OpenAIå¹³å°](https://platform.openai.com/)
2. æ³¨å†Œå¹¶éªŒè¯è´¦æˆ·
3. åœ¨API Keysé¡µé¢åˆ›å»ºæ–°å¯†é’¥
4. å¤åˆ¶å¯†é’¥åˆ°é…ç½®æ–‡ä»¶

**ä½¿ç”¨ç¤ºä¾‹ï¼š**
```python
# ç¯å¢ƒå˜é‡é…ç½®
export OPENAI_API_KEY="sk-your-key-here"
export OPENAI_MODEL="gpt-4"

# ä»£ç é…ç½®
config = {
    "api_key": "sk-your-key-here",
    "model": "gpt-4",
    "base_url": "https://api.openai.com/v1",
    "max_tokens": 4096
}
```

### 3. OpenRouter API

**ç‰¹ç‚¹ï¼š**
- èšåˆå¤šä¸ªæ¨¡å‹æä¾›å•†
- ç»Ÿä¸€APIæ¥å£
- ä»·æ ¼é€æ˜

**é…ç½®å‚æ•°ï¼š**
```json
{
  "name": "openrouter",
  "api_key": "sk-your-openrouter-api-key",
  "model_name": "openai/gpt-4",
  "base_url": "https://openrouter.ai/api/v1",
  "models": [
    "openai/gpt-4",
    "anthropic/claude-3-opus",
    "google/gemini-pro",
    "deepseek/deepseek-chat"
  ],
  "system_prompt": ""
}
```

**è·å–APIå¯†é’¥ï¼š**
1. è®¿é—® [OpenRouter](https://openrouter.ai/)
2. æ³¨å†Œå¹¶ç™»å½•è´¦æˆ·
3. åœ¨Keysé¡µé¢åˆ›å»ºAPIå¯†é’¥
4. å¤åˆ¶å¯†é’¥åˆ°é…ç½®æ–‡ä»¶

**ä½¿ç”¨ç¤ºä¾‹ï¼š**
```python
# ç¯å¢ƒå˜é‡é…ç½®
export OPENROUTER_API_KEY="sk-your-key-here"
export OPENROUTER_MODEL="openai/gpt-4"

# ä»£ç é…ç½®
config = {
    "api_key": "sk-your-key-here",
    "model": "openai/gpt-4",
    "base_url": "https://openrouter.ai/api/v1",
    "max_tokens": 4096,
    "headers": {
        "HTTP-Referer": "https://github.com/Long-Novel-GPT",
        "X-Title": "Long-Novel-GPT"
    }
}
```

### 4. æ™ºè°±AI API

**ç‰¹ç‚¹ï¼š**
- å›½äº§å¤§æ¨¡å‹
- ä¸­æ–‡ç†è§£èƒ½åŠ›å¼º
- å¤šæ¨¡æ€æ”¯æŒ

**é…ç½®å‚æ•°ï¼š**
```json
{
  "name": "zhipuai",
  "api_key": "your-zhipuai-api-key",
  "model_name": "glm-4-air",
  "base_url": null,
  "models": ["glm-4-air", "glm-4-flashx", "glm-4-plus", "glm-4v-plus"],
  "system_prompt": ""
}
```

**è·å–APIå¯†é’¥ï¼š**
1. è®¿é—® [æ™ºè°±AIå¼€æ”¾å¹³å°](https://open.bigmodel.cn/)
2. æ³¨å†Œå¹¶å®åè®¤è¯
3. åœ¨APIç®¡ç†é¡µé¢åˆ›å»ºå¯†é’¥
4. å¤åˆ¶å¯†é’¥åˆ°é…ç½®æ–‡ä»¶

**ä½¿ç”¨ç¤ºä¾‹ï¼š**
```python
# ç¯å¢ƒå˜é‡é…ç½®
export ZHIPUAI_API_KEY="your-key-here"
export ZHIPUAI_MODEL="glm-4-air"

# ä»£ç é…ç½®
config = {
    "api_key": "your-key-here",
    "model": "glm-4-air",
    "max_tokens": 4096
}
```

### 5. é˜¿é‡Œäº‘API

**ç‰¹ç‚¹ï¼š**
- é€šä¹‰åƒé—®ç³»åˆ—
- ä¼ä¸šçº§ç¨³å®šæ€§
- é•¿æ–‡æœ¬å¤„ç†

**é…ç½®å‚æ•°ï¼š**
```json
{
  "name": "aliyun",
  "api_key": "your-aliyun-api-key",
  "model_name": "qwen-max",
  "base_url": "https://dashscope.aliyuncs.com/api/v1",
  "models": ["qwen-max", "qwen-plus", "qwen-turbo", "qwen2.5-72b-instruct"],
  "system_prompt": ""
}
```

**è·å–APIå¯†é’¥ï¼š**
1. è®¿é—® [é˜¿é‡Œäº‘æ§åˆ¶å°](https://dashscope.console.aliyun.com/)
2. å¼€é€šçµç§¯æ¨¡å‹æœåŠ¡
3. åœ¨API-KEYç®¡ç†é¡µé¢åˆ›å»ºå¯†é’¥
4. å¤åˆ¶å¯†é’¥åˆ°é…ç½®æ–‡ä»¶

**ä½¿ç”¨ç¤ºä¾‹ï¼š**
```python
# ç¯å¢ƒå˜é‡é…ç½®
export DASHSCOPE_API_KEY="sk-your-key-here"
export QWEN_MODEL="qwen-max"

# ä»£ç é…ç½®
config = {
    "api_key": "sk-your-key-here",
    "model": "qwen-max",
    "base_url": "https://dashscope.aliyuncs.com/api/v1",
    "max_tokens": 4096
}
```

### 6. è±†åŒ…API

**ç‰¹ç‚¹ï¼š**
- å­—èŠ‚è·³åŠ¨å‡ºå“
- å¤šæ¨¡æ€èƒ½åŠ›
- é«˜è´¨é‡è¾“å‡º

**é…ç½®å‚æ•°ï¼š**
```json
{
  "name": "doubao",
  "api_key": "your-doubao-api-key",
  "model_name": "doubao-lite-32k",
  "base_url": "https://ark.cn-beijing.volces.com/api/v3",
  "models": ["doubao-lite-32k", "doubao-lite-128k", "doubao-pro-32k", "doubao-pro-128k"],
  "system_prompt": "",
  "endpoint_id": "your-endpoint-id"
}
```

**è·å–APIå¯†é’¥ï¼š**
1. è®¿é—® [ç«å±±å¼•æ“](https://console.volcengine.com/ark/)
2. å¼€é€šè±†åŒ…å¤§æ¨¡å‹æœåŠ¡
3. åˆ›å»ºæ¨ç†æ¥å…¥ç‚¹
4. å¤åˆ¶API Keyå’ŒEndpoint ID

**ä½¿ç”¨ç¤ºä¾‹ï¼š**
```python
# ç¯å¢ƒå˜é‡é…ç½®
export DOUBAO_API_KEY="your-key-here"
export DOUBAO_ENDPOINT_ID="your-endpoint-id"

# ä»£ç é…ç½®
config = {
    "api_key": "your-key-here",
    "model": "doubao-lite-32k",
    "endpoint_id": "your-endpoint-id",
    "base_url": "https://ark.cn-beijing.volces.com/api/v3",
    "max_tokens": 32000
}
```

### 7. Claude API

**ç‰¹ç‚¹ï¼š**
- Anthropicå‡ºå“
- é•¿æ–‡æœ¬ç†è§£èƒ½åŠ›å¼º
- å®‰å…¨æ€§é«˜

**é…ç½®å‚æ•°ï¼š**
```json
{
  "name": "claude",
  "api_key": "sk-your-claude-api-key",
  "model_name": "claude-3-5-sonnet-20241022",
  "base_url": "https://api.anthropic.com",
  "models": [
    "claude-3-opus-20240229",
    "claude-3-sonnet-20240229",
    "claude-3-haiku-20240307",
    "claude-3-5-sonnet-20241022",
    "claude-3-5-haiku-20241022"
  ],
  "system_prompt": ""
}
```

**è·å–APIå¯†é’¥ï¼š**
1. è®¿é—® [Anthropicæ§åˆ¶å°](https://console.anthropic.com/)
2. æ³¨å†Œå¹¶éªŒè¯è´¦æˆ·
3. åœ¨API Keysé¡µé¢åˆ›å»ºå¯†é’¥
4. å¤åˆ¶å¯†é’¥åˆ°é…ç½®æ–‡ä»¶

**ä½¿ç”¨ç¤ºä¾‹ï¼š**
```python
# ç¯å¢ƒå˜é‡é…ç½®
export ANTHROPIC_API_KEY="sk-your-key-here"
export CLAUDE_MODEL="claude-3-5-sonnet-20241022"

# ä»£ç é…ç½®
config = {
    "api_key": "sk-your-key-here",
    "model": "claude-3-5-sonnet-20241022",
    "base_url": "https://api.anthropic.com",
    "max_tokens": 4096
}
```

### 8. LM Studioï¼ˆæœ¬åœ°æ¨¡å‹ï¼‰

**ç‰¹ç‚¹ï¼š**
- æœ¬åœ°éƒ¨ç½²
- éšç§ä¿æŠ¤
- æ— ç½‘ç»œä¾èµ–

**é…ç½®å‚æ•°ï¼š**
```json
{
  "name": "lmstudio",
  "api_key": "lm-studio",
  "model_name": "your-local-model",
  "base_url": "http://localhost:1234/v1",
  "models": ["your-local-model"],
  "system_prompt": ""
}
```

**è®¾ç½®æ­¥éª¤ï¼š**
1. ä¸‹è½½å¹¶å®‰è£… [LM Studio](https://lmstudio.ai/)
2. ä¸‹è½½æ‰€éœ€çš„æ¨¡å‹æ–‡ä»¶
3. å¯åŠ¨æœ¬åœ°æœåŠ¡å™¨
4. é…ç½®APIç«¯ç‚¹

**ä½¿ç”¨ç¤ºä¾‹ï¼š**
```python
# ç¯å¢ƒå˜é‡é…ç½®
export LM_STUDIO_BASE_URL="http://localhost:1234/v1"
export LM_STUDIO_MODEL="your-local-model"

# ä»£ç é…ç½®
config = {
    "api_key": "lm-studio",
    "model": "your-local-model",
    "base_url": "http://localhost:1234/v1",
    "max_tokens": 4096
}
```

## é…ç½®æ–¹æ³•

### 1. ç¯å¢ƒå˜é‡é…ç½®

**åˆ›å»º.envæ–‡ä»¶ï¼š**
```bash
# å¤åˆ¶æ¨¡æ¿
cp .env.example .env

# ç¼–è¾‘é…ç½®
nano .env
```

**é…ç½®ç¤ºä¾‹ï¼š**
```env
# DeepSeek
DEEPSEEK_API_KEY=sk-your-deepseek-key
DEEPSEEK_MODEL=deepseek-chat

# OpenAI
OPENAI_API_KEY=sk-your-openai-key
OPENAI_MODEL=gpt-4

# æ™ºè°±AI
ZHIPUAI_API_KEY=your-zhipuai-key
ZHIPUAI_MODEL=glm-4-air

# é»˜è®¤æä¾›å•†
DEFAULT_PROVIDER=deepseek
```

### 2. åŠ¨æ€é…ç½®

**åˆ›å»ºruntime_config.jsonï¼š**
```json
{
  "current_provider": "deepseek",
  "providers": {
    "deepseek": {
      "name": "deepseek",
      "api_key": "sk-your-key",
      "model_name": "deepseek-chat",
      "base_url": "https://api.deepseek.com/v1",
      "models": ["deepseek-chat", "deepseek-coder"],
      "system_prompt": "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„å°è¯´åˆ›ä½œåŠ©æ‰‹ã€‚"
    }
  }
}
```

### 3. Webç•Œé¢é…ç½®

**é€šè¿‡Webç•Œé¢é…ç½®ï¼š**
1. å¯åŠ¨åº”ç”¨
2. è®¿é—®è®¾ç½®é¡µé¢
3. é€‰æ‹©AIæä¾›å•†
4. å¡«å†™APIå¯†é’¥
5. æµ‹è¯•è¿æ¥
6. ä¿å­˜é…ç½®

## é…ç½®éªŒè¯

### 1. åŸºæœ¬è¿æ¥æµ‹è¯•

```python
def test_api_connection(provider_name, config):
    """æµ‹è¯•APIè¿æ¥"""
    try:
        # æ ¹æ®æä¾›å•†é€‰æ‹©æµ‹è¯•æ–¹æ³•
        if provider_name == "deepseek":
            return test_deepseek_connection(config)
        elif provider_name == "openai":
            return test_openai_connection(config)
        elif provider_name == "zhipuai":
            return test_zhipuai_connection(config)
        # ... å…¶ä»–æä¾›å•†
        
    except Exception as e:
        return {"success": False, "error": str(e)}

def test_deepseek_connection(config):
    """æµ‹è¯•DeepSeekè¿æ¥"""
    import requests
    
    headers = {
        "Authorization": f"Bearer {config['api_key']}",
        "Content-Type": "application/json"
    }
    
    data = {
        "model": config["model_name"],
        "messages": [{"role": "user", "content": "Hello"}],
        "max_tokens": 10
    }
    
    response = requests.post(
        f"{config['base_url']}/chat/completions",
        headers=headers,
        json=data,
        timeout=30
    )
    
    if response.status_code == 200:
        return {"success": True, "message": "è¿æ¥æˆåŠŸ"}
    else:
        return {"success": False, "error": response.text}
```

### 2. æ¨¡å‹å¯ç”¨æ€§æ£€æŸ¥

```python
def check_model_availability(provider_name, config):
    """æ£€æŸ¥æ¨¡å‹å¯ç”¨æ€§"""
    try:
        # è·å–æ¨¡å‹åˆ—è¡¨
        models = get_available_models(provider_name, config)
        
        # æ£€æŸ¥é…ç½®çš„æ¨¡å‹æ˜¯å¦åœ¨å¯ç”¨åˆ—è¡¨ä¸­
        if config["model_name"] in models:
            return {"success": True, "models": models}
        else:
            return {
                "success": False,
                "error": f"æ¨¡å‹ {config['model_name']} ä¸å¯ç”¨",
                "available_models": models
            }
            
    except Exception as e:
        return {"success": False, "error": str(e)}
```

### 3. æƒé™å’Œé…é¢æ£€æŸ¥

```python
def check_api_quota(provider_name, config):
    """æ£€æŸ¥APIé…é¢"""
    try:
        # å‘é€ç®€å•è¯·æ±‚æ£€æŸ¥é…é¢
        response = send_test_request(provider_name, config)
        
        if response.get("success"):
            # æ£€æŸ¥å“åº”å¤´ä¸­çš„é…é¢ä¿¡æ¯
            quota_info = extract_quota_info(response.get("headers", {}))
            return {"success": True, "quota": quota_info}
        else:
            return {"success": False, "error": response.get("error")}
            
    except Exception as e:
        return {"success": False, "error": str(e)}
```

## è´¹ç”¨é…ç½®

### 1. è´¹ç”¨é™åˆ¶è®¾ç½®

```env
# è´¹ç”¨é™åˆ¶é…ç½®
API_HOURLY_LIMIT_RMB=100
API_DAILY_LIMIT_RMB=500
API_USD_TO_RMB_RATE=7.0
```

### 2. è´¹ç”¨ç›‘æ§

```python
def monitor_api_costs():
    """ç›‘æ§APIè´¹ç”¨"""
    from llm_api.mongodb_cost import get_model_cost_stats
    import datetime
    
    # è·å–æœ€è¿‘24å°æ—¶çš„è´¹ç”¨ç»Ÿè®¡
    end_time = datetime.datetime.now()
    start_time = end_time - datetime.timedelta(hours=24)
    
    stats = get_model_cost_stats(start_time, end_time)
    
    total_cost_rmb = 0
    for stat in stats:
        if stat['currency_symbol'] == '$':
            cost_rmb = stat['total_cost'] * 7.0  # USD to RMB
        else:
            cost_rmb = stat['total_cost']
        total_cost_rmb += cost_rmb
    
    print(f"æœ€è¿‘24å°æ—¶è´¹ç”¨: ï¿¥{total_cost_rmb:.2f}")
    
    # æ£€æŸ¥æ˜¯å¦è¶…è¿‡é™åˆ¶
    if total_cost_rmb > 500:  # æ—¥é™åˆ¶
        print("âš ï¸  è´¹ç”¨è¶…è¿‡æ—¥é™åˆ¶ï¼")
    
    return total_cost_rmb
```

### 3. è´¹ç”¨ç»Ÿè®¡

```python
def get_cost_statistics(days=7):
    """è·å–è´¹ç”¨ç»Ÿè®¡"""
    from llm_api.mongodb_cost import get_model_cost_stats
    import datetime
    
    end_time = datetime.datetime.now()
    start_time = end_time - datetime.timedelta(days=days)
    
    stats = get_model_cost_stats(start_time, end_time)
    
    cost_by_provider = {}
    for stat in stats:
        provider = stat['model'].split('/')[0] if '/' in stat['model'] else 'unknown'
        
        if provider not in cost_by_provider:
            cost_by_provider[provider] = {
                'total_cost': 0,
                'total_tokens': 0,
                'call_count': 0
            }
        
        cost_by_provider[provider]['total_cost'] += stat['total_cost']
        cost_by_provider[provider]['total_tokens'] += stat['total_tokens']
        cost_by_provider[provider]['call_count'] += stat['call_count']
    
    return cost_by_provider
```

## æœ€ä½³å®è·µ

### 1. å®‰å…¨é…ç½®

**ä¿æŠ¤APIå¯†é’¥ï¼š**
```bash
# è®¾ç½®æ–‡ä»¶æƒé™
chmod 600 .env
chmod 600 runtime_config.json

# ä½¿ç”¨ç¯å¢ƒå˜é‡
export API_KEY_FILE="/secure/path/to/keys"
```

**å¯†é’¥è½®æ¢ï¼š**
```python
def rotate_api_key(provider_name, old_key, new_key):
    """è½®æ¢APIå¯†é’¥"""
    # 1. æµ‹è¯•æ–°å¯†é’¥
    test_result = test_api_connection(provider_name, {"api_key": new_key})
    
    if not test_result["success"]:
        return {"success": False, "error": "æ–°å¯†é’¥æµ‹è¯•å¤±è´¥"}
    
    # 2. æ›´æ–°é…ç½®
    config_manager = get_config_manager()
    config_manager.update_provider_config(provider_name, {"api_key": new_key})
    
    # 3. ä¿å­˜é…ç½®
    config_manager.save_config_to_file()
    
    return {"success": True, "message": "å¯†é’¥è½®æ¢æˆåŠŸ"}
```

### 2. æ€§èƒ½ä¼˜åŒ–

**è¿æ¥æ± é…ç½®ï¼š**
```python
import httpx

# é…ç½®è¿æ¥æ± 
client = httpx.Client(
    timeout=30.0,
    limits=httpx.Limits(max_connections=100, max_keepalive_connections=20)
)
```

**è¯·æ±‚é‡è¯•ï¼š**
```python
import time
import random

def retry_api_call(func, max_retries=3, backoff_factor=1.0):
    """APIè°ƒç”¨é‡è¯•è£…é¥°å™¨"""
    def wrapper(*args, **kwargs):
        for attempt in range(max_retries):
            try:
                return func(*args, **kwargs)
            except Exception as e:
                if attempt == max_retries - 1:
                    raise e
                
                # æŒ‡æ•°é€€é¿
                delay = backoff_factor * (2 ** attempt) + random.uniform(0, 1)
                time.sleep(delay)
                
    return wrapper
```

### 3. é”™è¯¯å¤„ç†

**ç»Ÿä¸€é”™è¯¯å¤„ç†ï¼š**
```python
class APIError(Exception):
    """APIé”™è¯¯åŸºç±»"""
    def __init__(self, message, error_code=None, provider=None):
        self.message = message
        self.error_code = error_code
        self.provider = provider
        super().__init__(self.message)

class RateLimitError(APIError):
    """é™æµé”™è¯¯"""
    pass

class AuthenticationError(APIError):
    """è®¤è¯é”™è¯¯"""
    pass

class QuotaExceededError(APIError):
    """é…é¢è¶…é™é”™è¯¯"""
    pass

def handle_api_error(response, provider_name):
    """å¤„ç†APIé”™è¯¯"""
    if response.status_code == 401:
        raise AuthenticationError("APIå¯†é’¥æ— æ•ˆ", provider=provider_name)
    elif response.status_code == 429:
        raise RateLimitError("è¯·æ±‚è¿‡äºé¢‘ç¹", provider=provider_name)
    elif response.status_code == 402:
        raise QuotaExceededError("é…é¢å·²ç”¨å®Œ", provider=provider_name)
    else:
        raise APIError(f"APIè°ƒç”¨å¤±è´¥: {response.text}", provider=provider_name)
```

### 4. ç›‘æ§å’Œå‘Šè­¦

**è®¾ç½®ç›‘æ§ï¼š**
```python
class APIMonitor:
    def __init__(self):
        self.metrics = {
            'success_count': 0,
            'error_count': 0,
            'total_cost': 0,
            'response_times': []
        }
    
    def record_success(self, response_time, cost=0):
        self.metrics['success_count'] += 1
        self.metrics['total_cost'] += cost
        self.metrics['response_times'].append(response_time)
    
    def record_error(self, error_type):
        self.metrics['error_count'] += 1
        
        # å‘é€å‘Šè­¦
        if self.metrics['error_count'] > 10:
            self.send_alert(f"APIé”™è¯¯æ¬¡æ•°è¿‡å¤š: {error_type}")
    
    def send_alert(self, message):
        # å®ç°å‘Šè­¦é€»è¾‘ï¼ˆé‚®ä»¶ã€çŸ­ä¿¡ã€Webhookç­‰ï¼‰
        print(f"ğŸš¨ å‘Šè­¦: {message}")
```

## æ•…éšœæ’é™¤

### 1. å¸¸è§é”™è¯¯

**è®¤è¯å¤±è´¥ï¼š**
```
Error: 401 Unauthorized
åŸå› : APIå¯†é’¥æ— æ•ˆæˆ–è¿‡æœŸ
è§£å†³: æ£€æŸ¥å¹¶æ›´æ–°APIå¯†é’¥
```

**é™æµé”™è¯¯ï¼š**
```
Error: 429 Too Many Requests
åŸå› : è¯·æ±‚é¢‘ç‡è¿‡é«˜
è§£å†³: é™ä½è¯·æ±‚é¢‘ç‡æˆ–å‡çº§å¥—é¤
```

**é…é¢è¶…é™ï¼š**
```
Error: 402 Payment Required
åŸå› : APIé…é¢å·²ç”¨å®Œ
è§£å†³: å……å€¼æˆ–ç­‰å¾…é…é¢é‡ç½®
```

### 2. è¯Šæ–­å·¥å…·

**è¿æ¥è¯Šæ–­ï¼š**
```python
def diagnose_connection(provider_name, config):
    """è¯Šæ–­è¿æ¥é—®é¢˜"""
    results = {}
    
    # 1. æ£€æŸ¥ç½‘ç»œè¿æ¥
    results['network'] = check_network_connectivity(config['base_url'])
    
    # 2. æ£€æŸ¥DNSè§£æ
    results['dns'] = check_dns_resolution(config['base_url'])
    
    # 3. æ£€æŸ¥SSLè¯ä¹¦
    results['ssl'] = check_ssl_certificate(config['base_url'])
    
    # 4. æ£€æŸ¥APIå¯†é’¥
    results['auth'] = check_api_authentication(provider_name, config)
    
    # 5. æ£€æŸ¥APIçŠ¶æ€
    results['api_status'] = check_api_status(provider_name, config)
    
    return results
```

**æ€§èƒ½è¯Šæ–­ï¼š**
```python
def diagnose_performance(provider_name, config):
    """è¯Šæ–­æ€§èƒ½é—®é¢˜"""
    import time
    
    response_times = []
    
    # å‘é€10ä¸ªæµ‹è¯•è¯·æ±‚
    for i in range(10):
        start_time = time.time()
        try:
            response = send_test_request(provider_name, config)
            response_time = time.time() - start_time
            response_times.append(response_time)
        except Exception as e:
            print(f"æµ‹è¯•è¯·æ±‚ {i+1} å¤±è´¥: {e}")
    
    if response_times:
        avg_time = sum(response_times) / len(response_times)
        max_time = max(response_times)
        min_time = min(response_times)
        
        print(f"å¹³å‡å“åº”æ—¶é—´: {avg_time:.2f}s")
        print(f"æœ€å¤§å“åº”æ—¶é—´: {max_time:.2f}s")
        print(f"æœ€å°å“åº”æ—¶é—´: {min_time:.2f}s")
        
        if avg_time > 5.0:
            print("âš ï¸  å“åº”æ—¶é—´è¿‡é•¿ï¼Œå¯èƒ½å­˜åœ¨æ€§èƒ½é—®é¢˜")
    
    return response_times
```

## é…ç½®æ¨¡æ¿

### 1. ç”Ÿäº§ç¯å¢ƒé…ç½®

```json
{
  "current_provider": "deepseek",
  "providers": {
    "deepseek": {
      "name": "deepseek",
      "api_key": "${DEEPSEEK_API_KEY}",
      "model_name": "deepseek-chat",
      "base_url": "https://api.deepseek.com/v1",
      "models": ["deepseek-chat", "deepseek-coder"],
      "system_prompt": "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„å°è¯´åˆ›ä½œåŠ©æ‰‹ï¼Œè¯·éµå¾ªä»¥ä¸‹åŸåˆ™ï¼š1.åˆ›ä½œå†…å®¹ç§¯æå‘ä¸Š 2.æ–‡ç¬”æµç•…ä¼˜ç¾ 3.æƒ…èŠ‚å¼•äººå…¥èƒœ"
    },
    "openai": {
      "name": "openai", 
      "api_key": "${OPENAI_API_KEY}",
      "model_name": "gpt-4",
      "base_url": "https://api.openai.com/v1",
      "models": ["gpt-4", "gpt-3.5-turbo"],
      "system_prompt": "You are a professional novel writing assistant."
    }
  }
}
```

### 2. å¼€å‘ç¯å¢ƒé…ç½®

```json
{
  "current_provider": "lmstudio",
  "providers": {
    "lmstudio": {
      "name": "lmstudio",
      "api_key": "lm-studio",
      "model_name": "local-model",
      "base_url": "http://localhost:1234/v1",
      "models": ["local-model"],
      "system_prompt": "å¼€å‘æµ‹è¯•ç¯å¢ƒ"
    }
  }
}
```

### 3. æµ‹è¯•ç¯å¢ƒé…ç½®

```json
{
  "current_provider": "mock",
  "providers": {
    "mock": {
      "name": "mock",
      "api_key": "test-key",
      "model_name": "mock-model",
      "base_url": "http://localhost:8080/mock",
      "models": ["mock-model"],
      "system_prompt": "æµ‹è¯•ç¯å¢ƒ"
    }
  }
}
```

## æ€»ç»“

é€šè¿‡æœ¬æ–‡æ¡£ï¼Œæ‚¨åº”è¯¥èƒ½å¤Ÿï¼š

1. **äº†è§£æ‰€æœ‰æ”¯æŒçš„APIæä¾›å•†**ï¼šç‰¹ç‚¹ã€è·å–æ–¹æ³•ã€é…ç½®å‚æ•°
2. **æŒæ¡é…ç½®æ–¹æ³•**ï¼šç¯å¢ƒå˜é‡ã€åŠ¨æ€é…ç½®ã€Webç•Œé¢é…ç½®
3. **è¿›è¡Œé…ç½®éªŒè¯**ï¼šè¿æ¥æµ‹è¯•ã€æ¨¡å‹æ£€æŸ¥ã€æƒé™éªŒè¯
4. **å®æ–½æœ€ä½³å®è·µ**ï¼šå®‰å…¨é…ç½®ã€æ€§èƒ½ä¼˜åŒ–ã€é”™è¯¯å¤„ç†
5. **è§£å†³å¸¸è§é—®é¢˜**ï¼šæ•…éšœæ’é™¤ã€è¯Šæ–­å·¥å…·ã€é…ç½®æ¨¡æ¿

æ­£ç¡®çš„APIé…ç½®æ˜¯Long-Novel-GPTæ­£å¸¸è¿è¡Œçš„å…³é”®ï¼Œè¯·æ ¹æ®å®é™…éœ€æ±‚é€‰æ‹©åˆé€‚çš„æä¾›å•†å’Œé…ç½®æ–¹æ¡ˆã€‚ 