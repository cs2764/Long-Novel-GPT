import httpx
from openai import OpenAI
from .chat_messages import ChatMessages

# Pricing reference: https://openai.com/api/pricing/
gpt_model_config = {
    "gpt-4o": {
        "Pricing": (2.50/1000, 10.00/1000),
        "currency_symbol": '$',
    },
    "gpt-4o-mini": {
        "Pricing": (0.15/1000, 0.60/1000),
        "currency_symbol": '$',
    },
    "o1-preview": {
        "Pricing": (15/1000, 60/1000),
        "currency_symbol": '$',
        "supports_reasoning": True,
    },
    "o1-mini": {
        "Pricing": (3/1000, 12/1000),
        "currency_symbol": '$',
        "supports_reasoning": True,
    },
    "o1-preview-2024-09-12": {
        "Pricing": (15/1000, 60/1000),
        "currency_symbol": '$',
        "supports_reasoning": True,
    },
    "o1-mini-2024-09-12": {
        "Pricing": (3/1000, 12/1000),
        "currency_symbol": '$',
        "supports_reasoning": True,
    },
}
# https://platform.openai.com/docs/guides/reasoning

def stream_chat_with_gpt(messages, model='gpt-3.5-turbo-1106', response_json=False, api_key=None, base_url=None, max_tokens=4_096, n=1, proxies=None, timeout=300):
    import traceback
    import json
    import requests
    import time
    
    # è¯¦ç»†æ—¥å¿—è®°å½•APIè°ƒç”¨ä¿¡æ¯
    print(f"=== OpenAI API Call Details ===")
    print(f"Model: {model}")
    print(f"Base URL: {base_url}")
    print(f"API Key: {'***' + api_key[-8:] if api_key and len(api_key) > 8 else 'None'}")
    print(f"Max Tokens: {max_tokens}")
    print(f"Timeout: {timeout}s")
    print(f"Response JSON: {response_json}")
    print(f"Messages Count: {len(messages)}")
    print(f"First Message: {json.dumps(messages[0] if messages else {}, ensure_ascii=False)[:200]}...")
    print(f"Proxies: {proxies}")
    
    # æ£€æŸ¥æ˜¯å¦æ˜¯LM Studioæœ¬åœ°æ¨¡å‹
    is_local_model = base_url and ('localhost' in base_url or '127.0.0.1' in base_url)
    if is_local_model:
        print(f"ğŸ  æ£€æµ‹åˆ°LM Studioæœ¬åœ°æ¨¡å‹ï¼Œä½¿ç”¨å»¶é•¿çš„è¶…æ—¶æ—¶é—´: {timeout}s")
    
    if api_key is None:
        error_msg = 'æœªæä¾›æœ‰æ•ˆçš„ api_keyï¼'
        print(f"âŒ API Key Error: {error_msg}")
        raise Exception(error_msg)
    
    # æ„å»ºå®é™…çš„HTTPè¯·æ±‚è¯¦ç»†ä¿¡æ¯
    api_url = f"{base_url or 'https://api.openai.com/v1'}/chat/completions"
    
    headers = {
        "Authorization": f"Bearer {api_key}",
        "Content-Type": "application/json"
    }
    
    if base_url and "openrouter.ai" in base_url:
        headers.update({
            "HTTP-Referer": "https://github.com/Long-Novel-GPT",
            "X-Title": "Long-Novel-GPT"
        })
    
    request_body = {
        'stream': True,
        'model': model, 
        'messages': messages, 
        'max_tokens': max_tokens,
        'n': n
    }
    
    if response_json:
        request_body['response_format'] = {
            "type": "json_schema",
            "json_schema": {
                "name": "response_schema",
                "schema": {
                    "type": "object",
                    "properties": {
                        "text": {"type": "string"}
                    },
                    "required": ["text"],
                    "additionalProperties": True
                }
            }
        }
        
    # æ˜¾ç¤ºå®é™…å‘é€çš„HTTPè¯·æ±‚è¯¦ç»†ä¿¡æ¯
    print(f"\nğŸŒ === HTTP Request Details ===")
    print(f"URL: {api_url}")
    print(f"Method: POST")
    print(f"Headers:")
    for key, value in headers.items():
        if key.lower() == 'authorization':
            print(f"  {key}: Bearer ***{value.split()[-1][-8:] if len(value.split()) > 1 else '***'}")
        else:
            print(f"  {key}: {value}")
    
    print(f"Request Body:")
    # ä¸ºäº†æ˜¾ç¤ºï¼Œåˆ›å»ºä¸€ä¸ªå®‰å…¨çš„è¯·æ±‚ä½“å‰¯æœ¬
    safe_body = request_body.copy()
    safe_body['messages'] = [
        {**msg, 'content': msg['content'][:100] + '...' if len(msg.get('content', '')) > 100 else msg.get('content', '')}
        for msg in messages
    ]
    print(json.dumps(safe_body, indent=2, ensure_ascii=False))
    print(f"=== End HTTP Request Details ===\n")
    
    client_params = {
        "api_key": api_key,
    }

    if base_url:
        client_params['base_url'] = base_url
        print(f"âœ… Using custom base URL: {base_url}")

    # é…ç½®HTTPå®¢æˆ·ç«¯çš„è¶…æ—¶è®¾ç½®
    httpx_timeout = httpx.Timeout(timeout=timeout)
    if proxies:
        httpx_client = httpx.Client(proxy=proxies, timeout=httpx_timeout)
        client_params["http_client"] = httpx_client
        print(f"âœ… Using proxy: {proxies}")
    else:
        httpx_client = httpx.Client(timeout=httpx_timeout)
        client_params["http_client"] = httpx_client
        print(f"âœ… Using timeout: {timeout}s")
    
    try:
        client = OpenAI(**client_params)
        print("âœ… OpenAI client created successfully")

        # æ£€æŸ¥æ˜¯å¦ä¸ºo1ç³»åˆ—æ¨¡å‹ï¼ˆæ”¯æŒæ€è€ƒåŠŸèƒ½ï¼‰
        is_reasoning_model = model.startswith('o1-') or model in ['o1-preview', 'o1-mini']
        
        if is_reasoning_model and messages[0]['role'] == 'system':
            print(f"ğŸ”„ Converting system message for reasoning model: {model}")
            messages[0:1] = [{'role': 'user', 'content': messages[0]['content']}, {'role': 'assistant', 'content': ''}]
        
        request_params = {
            'stream': True,
            'model': model, 
            'messages': messages, 
            'max_tokens': max_tokens,
            'n': n
        }
        
        # Only add response_format if response_json is True
        if response_json:
            request_params['response_format'] = {
                "type": "json_schema",
                "json_schema": {
                    "name": "response_schema",
                    "schema": {
                        "type": "object",
                        "properties": {
                            "text": {"type": "string"}
                        },
                        "required": ["text"],
                        "additionalProperties": True
                    }
                }
            }
        
        print(f"ğŸš€ Sending request to {api_url}")
        start_time = time.time()
        
        chatstream = client.chat.completions.create(**request_params)
        
        print(f"âœ… API request initiated successfully in {time.time() - start_time:.2f}s, starting to stream response")
        
        messages.append({'role': 'assistant', 'content': ''})
        content = ['' for _ in range(n)]
        chunk_count = 0
        first_chunk_time = None
        
        for part in chatstream:
            chunk_count += 1
            if first_chunk_time is None:
                first_chunk_time = time.time()
                print(f"ğŸ“¦ First chunk received in {first_chunk_time - start_time:.2f}s")
            
            if chunk_count <= 3:  # Log first few chunks for debugging
                print(f"ğŸ“¦ Chunk #{chunk_count}: {str(part)[:200]}...")
            
            for choice in part.choices:
                # å¤„ç†å…·æœ‰æ€è€ƒåŠŸèƒ½çš„æ¨¡å‹ï¼ˆå¦‚o1ç³»åˆ—ï¼‰
                if hasattr(choice.delta, 'content') and choice.delta.content:
                    content[choice.index] += choice.delta.content
                
                # è¿‡æ»¤æ‰æ€è€ƒè¿‡ç¨‹ï¼Œåªä¿ç•™å®é™…çš„å›ç­”å†…å®¹
                # å¯¹äºo1ç³»åˆ—æ¨¡å‹ï¼Œæ€è€ƒè¿‡ç¨‹åœ¨reasoningå­—æ®µä¸­ï¼Œæˆ‘ä»¬åªå–contentå­—æ®µ
                if hasattr(choice.delta, 'reasoning') and choice.delta.reasoning:
                    # æ€è€ƒè¿‡ç¨‹ä¸æ·»åŠ åˆ°æœ€ç»ˆå†…å®¹ä¸­ï¼Œåªè®°å½•ç”¨äºè°ƒè¯•
                    if chunk_count <= 3:
                        print(f"ğŸ§  Reasoning chunk #{chunk_count}: {str(choice.delta.reasoning)[:100]}...")
                
                # å¯¹æœ€ç»ˆå†…å®¹è¿›è¡Œæ€è€ƒè¿‡ç¨‹è¿‡æ»¤ï¼ˆå¤„ç† <think> </think> ç­‰æ ‡ç­¾ï¼‰
                from prompts.prompt_utils import filter_thinking_process
                filtered_content = content if n > 1 else content[0]
                if isinstance(filtered_content, str):
                    filtered_content = filter_thinking_process(filtered_content)
                elif isinstance(filtered_content, list):
                    filtered_content = [filter_thinking_process(c) if isinstance(c, str) else c for c in filtered_content]
                
                messages[-1]['content'] = filtered_content
                yield messages
        
        total_time = time.time() - start_time
        print(f"âœ… API call completed successfully in {total_time:.2f}s, received {chunk_count} chunks")
        return messages
        
    except Exception as e:
        print(f"âŒ API Call Failed: {type(e).__name__}: {str(e)}")
        print(f"ğŸ“ Full traceback:")
        traceback.print_exc()
        
        # å°è¯•æå–æ›´è¯¦ç»†çš„é”™è¯¯ä¿¡æ¯
        if hasattr(e, 'response'):
            print(f"ğŸ” HTTP Response Details:")
            print(f"  Status Code: {getattr(e.response, 'status_code', 'Unknown')}")
            print(f"  Headers: {dict(getattr(e.response, 'headers', {}))}")
            try:
                response_text = e.response.text if hasattr(e.response, 'text') else str(e.response)
                print(f"  Response Body: {response_text[:1000]}...")
            except:
                print(f"  Response Body: Unable to read")
        
        # é‡æ–°æŠ›å‡ºå¼‚å¸¸ï¼Œä½†åŒ…å«æ›´å¤šä¿¡æ¯
        raise Exception(f"OpenAI APIè°ƒç”¨å¤±è´¥ - {type(e).__name__}: {str(e)}")
        
    finally:
        print(f"=== API Call Finished ===\n")

    
if __name__ == '__main__':
    pass
